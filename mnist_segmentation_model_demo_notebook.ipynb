{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Segmentation model demo for MNIST dataset on IMX8M Plus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEAZYXvZU_XG"
      },
      "source": [
        "## Library imports and drive mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "zN4yVFK5-0Bf"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow\n",
        "! pip install -q tensorflow-model-optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yJwIonXEVJo6"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tensorflow version \",tf.__version__)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "write_path = \"/content/drive/MyDrive/mnist_demo/\" # change or set as per drive for saving models and sample images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uq9sCdNPfMw",
        "outputId": "1f4d4510-c0e8-48ec-82d6-b53440f35ce9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version  2.8.2\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psViY5PRDurp"
      },
      "source": [
        "## Base model training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model definition**"
      ],
      "metadata": {
        "id": "zYGX2fWA78fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT = 28\n",
        "WIDTH = 28\n",
        "N_CLASSES = 10\n",
        "def seg_model_function(interpolation):\n",
        "  cnn_filters = 32\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Conv2D(cnn_filters, (2, 2), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(HEIGHT, WIDTH,1), name = \"input\"))\n",
        "  model.add(keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "  model.add(keras.layers.Conv2D(cnn_filters, (2, 2), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(keras.layers.MaxPooling2D((2, 2), padding='same'))\n",
        "  model.add(keras.layers.Conv2D(cnn_filters, (2, 2), strides=(2,2), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(keras.layers.Conv2D(8, (2, 2), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(keras.layers.UpSampling2D((2, 2), interpolation=interpolation))\n",
        "  model.add(keras.layers.Conv2D(cnn_filters, (2, 2), activation='relu'))\n",
        "  model.add(keras.layers.UpSampling2D((2, 2), interpolation=interpolation))\n",
        "  model.add(keras.layers.Conv2D(cnn_filters, (2, 2), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(keras.layers.UpSampling2D((2, 2), interpolation=interpolation))\n",
        "  model.add(keras.layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same'))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(units = N_CLASSES, activation ='softmax', name = \"output\"))\n",
        "\n",
        "  return model    \n"
      ],
      "metadata": {
        "id": "P9eWENwRjJmQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model training**"
      ],
      "metadata": {
        "id": "fdgjm1-w7_e0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbY-KGMPvbW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b9bc8f-c59e-43de-c2f5-78be440da821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (Conv2D)              (None, 28, 28, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 14, 14, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 4, 4, 32)          4128      \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 4, 4, 8)           1032      \n",
            "                                                                 \n",
            " up_sampling2d_24 (UpSamplin  (None, 8, 8, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 7, 7, 32)          1056      \n",
            "                                                                 \n",
            " up_sampling2d_25 (UpSamplin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 14, 14, 32)        4128      \n",
            "                                                                 \n",
            " up_sampling2d_26 (UpSamplin  (None, 28, 28, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 28, 28, 1)         129       \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,611\n",
            "Trainable params: 22,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3093 - accuracy: 0.9037\n",
            "Epoch 2/5\n",
            "1789/1875 [===========================>..] - ETA: 0s - loss: 0.1117 - accuracy: 0.9648"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "interpolation_used = \"nearest\" # check and compare \"bilinear\" vs \"nearest\" upsampling2d implementions on IMX8MP\n",
        "base_model = seg_model_function(interpolation_used)\n",
        "base_model.summary()\n",
        "\n",
        "# Compile and train the model\n",
        "base_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "base_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs = 5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample inference to verify the trained model"
      ],
      "metadata": {
        "id": "reYEjl8Y8BmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Generate reconstructions\n",
        "num_samples = 5\n",
        "samples = test_images[:num_samples]\n",
        "true_labels = test_labels[:num_samples]\n",
        "predictions = base_model.predict(samples)\n",
        "\n",
        "# Plot the results\n",
        "for i in np.arange(0, num_samples):\n",
        "  sample = samples[i,:, :]\n",
        "  prediction = np.argmax(predictions[i])\n",
        "  true_label = np.amax(true_labels[i])\n",
        "  fig, axes = plt.subplots(1, 1)\n",
        "  axes.imshow(sample)\n",
        "  fig.suptitle(f'true = {true_label}, predicted = {prediction}')\n",
        "  plt.show()\n",
        "\n",
        "# save samples and labels as pkl file for running inference on imx8mp\n",
        "labels = true_labels\n",
        "pkl_file = write_path + \"mnist_samples_labels.pkl\"\n",
        "with open(pkl_file, 'wb') as fptr:\n",
        "  pickle.dump(samples,fptr)\n",
        "  pickle.dump(labels,fptr)\n"
      ],
      "metadata": {
        "id": "4-Ah9Ldn2-iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post training quantization into INT8 format"
      ],
      "metadata": {
        "id": "bMp6scQv8Dww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ref_data_gen_v2():\n",
        "    for loop_var in range(1000):\n",
        "        sample = train_images[loop_var]\n",
        "        sample = sample.reshape(BATCH_SIZE,HEIGHT,WIDTH,1)\n",
        "        sample = sample.astype(np.float32)\n",
        "        yield [sample]\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "input_name = base_model.input_names[0]\n",
        "index = base_model.input_names.index(input_name)\n",
        "base_model.inputs[index].set_shape([BATCH_SIZE, HEIGHT, WIDTH, 1]) # to avoid dynamic tensors in tflite model, use 1 as batch size\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = ref_data_gen_v2\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.experimental_new_converter = True\n",
        "quantized_model = converter.convert()\n",
        "# save model in .tflite format for running inference on imx8mp\n",
        "model_name =  \"mnist_\" + interpolation_used + \"_demo_ptq.tflite\"\n",
        "open(write_path + model_name, \"wb\").write(quantized_model)"
      ],
      "metadata": {
        "id": "ObrpRHYR4hG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the quantized model"
      ],
      "metadata": {
        "id": "0t5ZqxKz8c3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verify that the operations are in INT8 format\n",
        "tf.lite.experimental.Analyzer.analyze(model_content=quantized_model)"
      ],
      "metadata": {
        "id": "dZpC3jPb8gq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mnist_segmentation_model_demo_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}